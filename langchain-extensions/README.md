# Langchain Extensions 

## Overview

The Langchain Community module provides a comprehensive suite of extensions for handling various document formats. 
These extensions are designed to integrate seamlessly with the existing Langchain ecosystem, enhancing its capabilities to meet specific business and customer needs. The module includes custom file handlers and loaders for a wide range of document types, making it easier for developers to add and process documents in their applications.

## Installation

#### 1. pip
```bash
pip install --upgrade pip
pip install git+https://bitbucket.org/crowdworks_dev/langchain-extensions.git
```

#### 2. poetry
```bash
poetry add git+https://bitbucket.org/crowdworks_dev/langchain-extensions.git
```

## Features

### 1. language_models

#### 1.1 Hyperclova, Mixtral and etc..

langchain ê³¼ 100% í˜¸í™˜ ë˜ëŠ” HyperClova ë° ê¸°íƒ€ ëª¨ë¸ì…ë‹ˆë‹¤.
ì•„ë˜ Snippet ì„ ì¤€ë¹„í•´ ë‘ì—ˆìœ¼ë‹ˆ ì°¸ì¡° ë°”ëë‹ˆë‹¤.

```python
from langchain.schema import StrOutputParser
from langchain_community.llms.openai import OpenAI
from langchain_core.prompts import ChatPromptTemplate

from langchain_extensions.language_models import HyperClova

CLOVASTUDIO_API_KEY = "ğŸ˜"

APIGW_API_KEY = "ğŸ˜"

OPENAI_API_KEY = "ğŸ˜"

prompt = ChatPromptTemplate.from_template("what is the city {person} is from?")

# Note: ëŒ€ì²´í•´ë„ ê·¸ëŒ€ë¡œ ë™ì‘ ê°€ëŠ¥!
# model = OpenAI(
#     api_key=OPENAI_API_KEY,
#     streaming=True,
# )

model = HyperClova(
    clovastudio_api_key=CLOVASTUDIO_API_KEY,
    apigw_api_key=APIGW_API_KEY,
)

chain = prompt | model | StrOutputParser()
invocation = chain.invoke({"person": "obama"})
print(invocation)
# AI(ğŸ¤–): Obama is from Honolulu.


stream = chain.stream({"person": "obama"})
for s in stream:
    print(s, end="")
# AI(ğŸ¤–): Obama is from Honolulu.
```


#### 1.2 History feature
ë‹¹ì—°í•˜ê²Œë„ íˆìŠ¤í† ë¦¬ ê¸°ëŠ¥ê¹Œì§€ ëª¨ë‘ langchain ê¸°ëŠ¥ì„ í†µí•©í•´ì„œ ì‚¬ìš© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```python

runnable = prompt | mixtral | StrOutputParser()
chain = RunnableWithMessageHistory(
    runnable,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history",
)
```
ì•„ë˜ì™€ ê°™ì´ íˆìŠ¤í† ë¦¬ ê¸°ë¡ì´ ë‚¨ê²Œ ë©ë‹ˆë‹¤.
```python
[
    HumanMessage(content="hi!", additional_kwargs={}, example=False),
    AIMessage(content="what`s up?", additional_kwargs={}, example=False),
    HumanMessage(content="I love you", additional_kwargs={}, example=False),
    AIMessage(content="what are you talking about?", additional_kwargs={}, example=False)
]
```

### 2. Knowledge Compiler
`langchain-extensions`ëŠ” SOTAì— ê·¼ì ‘í•œ ì—¬ëŸ¬ ë…¼ë¬¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ê°œë°œí•œ `Knowledge Compiler` ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. 
- [https://arxiv.org/abs/2207.06300 í˜„ì¬ ê°œë°œì¤‘ì¸ Knowledge Compiler ë…¼ë¬¸ ìë£Œ](https://arxiv.org/abs/2207.06300)
- [Re2G bitbucket for source code (under development..)](https://bitbucket.org/crowdworks_dev/re2g/src/master/)
- ì¶”ìƒí™” ëœ Rerank feature ë“¤ì„ ì–¸ì œë“  ìƒˆë¡­ê²Œ ì¶”ê°€ ë° ë³€ê²½ì´ ê°€ëŠ¥í•˜ë©° ì‹¤ì œ ì‚¬ìš© ì‹œ ì˜ ì‘ë™í•˜ì§€ ì•ŠëŠ” Retrieval ë¶€ë¶„ë“¤ì„ ì‰½ê²Œ ë³´ì™„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```python
from langchain_extensions.knowledge_compiler import KnowledgeCompiler

k_compiler = KnowledgeCompiler(prompt=prompt, retriever=retriever)

# ì™„ì „íˆ ë­ì²´ì¸ì— ë…¹ì•„ë“  knowledge compiler ì‚¬ìš© ì˜ˆì‹œ
# í–¥ìƒ ëœ ê²€ìƒ‰ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
chain = k_compiler | model | StrOutputParser()
stream = chain.stream()

for token in stream:
    print(token, end="")

# AI(ğŸ¤–): ì™€! ì •ë³´ë¥¼ ì˜ ì£¼ë‹ˆ ë‹µë³€í•˜ê¸° ë„ˆë¬´ ì‰½ë‹¤.
```


### 3. Mixin classes

#### 3.1 DefaultChromaFileHandler 
A versatile handler that supports adding documents from various formats, 
including CSV, PDF, Markdown, HTML, Word, and Excel, to the Chroma vector store. 
This handler leverages the document loaders to read files, extract content, 
and update document metadata before adding them to the vector store.

- ì¼ë°˜ì ì¸ langchain_community ì˜ Chroma ì‚¬ìš© ì‹œ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.
```
from langchain_community.vectorstores import Chroma
```

- í•˜ì§€ë§Œ í•´ë‹¹ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜ í›„ ì•„ë˜ì™€ ê°™ì´ ì‚¬ìš© ì‹œ ì¶”ê°€ í™•ì¥ ëœ ê¸°ëŠ¥ë“¤ì„ ì´ìš© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```
from langchain_extensions.vectorstores import Chroma

chroma = Chroma()

# í™•ì¥ ëœ chroma functions example 1
chroma.add_csv("path/to/csv/file.csv")

# í™•ì¥ ëœ chroma functions example 2  
with open("path/to/text/file.csv", "r") as f:
    file_bytes = f.read()
    chroma.add_csv(file_bytes)  
```

#### 3.2 Custom Functionality

- **Mixin classes**: 
An example class that demonstrates how to extend the Langchain module with custom file handling capabilities. 
This class is a mix-in that combines the features of Chroma with the DefaultChromaFileHandler, 
showcasing how to add documents from supported formats directly to a vector store for further processing or search capabilities.

- ì•„ë˜ëŠ” ì‹¤ì œ Default Chroma Mixin ì´ êµ¬í˜„ ëœ ì˜ˆì‹œ ì…ë‹ˆë‹¤.
ì•„ë˜ì™€ ë§ˆì°¬ê°€ì§€ë¡œ `ChromaDefaultFileHandlerMixin` ì„ ì›í•˜ëŠ” Mixin class ë¡œ ë³€ê²½ í•˜ì‹œë©´
ë³€ê²½ ë° í™•ì¥ ëœ Chroma ë¥¼ ìì²´ì ìœ¼ë¡œ Custom í•˜ì—¬ ì‚¬ìš© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```python
from langchain_community.vectorstores.chroma import Chroma as OriginalChroma

from langchain_extensions.mixins import ChromaDefaultFileHandlerMixin


class Chroma(OriginalChroma, ChromaDefaultFileHandlerMixin):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

```

#### 3.3 Use apply()

- ë³„ë„ì˜ ì¡°ì‘ ì—†ì´ apply ë¥¼ í†µí•´ì„œ ê³§ë°”ë¡œ mixin ëœ ê°ì²´ë¥¼ ì‚¬ìš© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
ChromaMixin = ChromaDefaultFileHandlerMixin.apply(Chroma)
chroma = ChromaMixin(persist_directory="/tmp/rag-chroma")

assert [
    "add_excel",
    "add_hangul",
    "add_html",
    "add_images",
    "add_json",
    "add_markdown",
    "add_pdf",
    "add_ppt",
    "add_word",
    "_add_by_loader",
] == dir(chroma)
```

##### 3.4 Abstract classes

from langchain_extensions.mixins import AbcFileHandler
ë¥¼ í™œìš©í•˜ì—¬ ìì‹ ë§Œì˜ ë©‹ì§„ `File handler` ë¥¼ êµ¬ì¶• í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
```python
import abc

class AbcFileHandler(abc.ABC):
    def add_csv(
        self,
        file_or_path: str | bytes,
        metadata: dict = None,
        collection: str = "default",
        segment: str = "default",
    ):
        raise NotImplementedError

    def add_pdf(
        self,
        file_or_path: str | bytes,
        metadata: dict = None,
        collection: str = "default",
        segment: str = "default",
    ):
        raise NotImplementedError

    def add_markdown(
        self,
        file_or_path: str | bytes,
        metadata: dict = None,
        collection: str = "default",
        segment: str = "default",
    ):
        raise NotImplementedError

    def add_json(
        self,
        file_or_path: str | bytes,
        metadata: dict = None,
        collection: str = "default",
        segment: str = "default",
    ):
        raise NotImplementedError

    def add_html(
        self,
        file_or_path: str | bytes,
        metadata: dict = None,
        collection: str = "default",
        segment: str = "default",
    ):
        raise NotImplementedError

    def add_ppt(
        self,
        file_or_path: str | bytes,
        metadata: dict = None,
        collection: str = "default",
        segment: str = "default",
    ):
        raise NotImplementedError

    def add_hangul(
        self,
        file_or_path: str | bytes,
        metadata: dict = None,
        collection: str = "default",
        segment: str = "default",
    ):
        raise NotImplementedError

    def add_word(
        self,
        file_or_path: str | bytes,
        metadata: dict = None,
        collection: str = "default",
        segment: str = "default",
    ):
        raise NotImplementedError

    def add_excel(
        self,
        file_or_path: str | bytes,
        metadata: dict = None,
        collection: str = "default",
        segment: str = "default",
    ):
        raise NotImplementedError


```

### 4. Custom Embedding
OpenAI ì˜ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ Clova ë° ë‹¤ë¥¸ Custom Model ë“¤ì˜ ì„ë² ë”© ì‚¬ìš©ê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤.

```python
from langchain_extensions.embeddings.naver import HyperClovaEmbeddings
from langchain_community.vectorstores import Chroma

API_KEY = "ğŸ˜"

embedding = HyperClovaEmbeddings(api_key=API_KEY)
chroma = Chroma(embedding_function=embedding)
```

```python
# hyperclova embedding ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì˜ í…ìŠ¤íŠ¸ë¥¼ vectorize í•©ë‹ˆë‹¤.
chroma.add_csv("path/to/csv/file.csv")

retriever = chroma.as_retriever(search_type="ip")
retriever.get_relevant_documents(query)[0]
```

```python
Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while youâ€™re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, Iâ€™d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyerâ€”an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nationâ€™s top legal minds, who will continue Justice Breyerâ€™s legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})
```

### 5. Papers ëª¨ë“ˆí™”
#### 5.1 RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval

https://arxiv.org/abs/2401.18059
##### 5.1.1 RAPTOR ì‚¬ìš©ë²•
1. .env file ì— openai_api_key ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.
2. ê·¸ ë’¤ ì•„ë˜ì™€ ê°™ì´ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.
```python
from bs4 import BeautifulSoup as Soup
from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader

from langchain_extensions.papers import raptor


def extractor(page):
    return Soup(page, "html.parser").text


url = "https://python.langchain.com/docs/expression_language/"

loader = RecursiveUrlLoader(url=url, max_depth=20, extractor=extractor)
docs = loader.load()

docs_texts = [d.page_content for d in docs]
very_long_text = "\n".join(docs_texts)
results = raptor.raptornize(very_long_text, level=1, n_levels=3)
print(results)
```

3. async ì˜ ê²½ìš° `araptornize` ë¥„ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.
```python
results = await raptor.araptornize(very_long_text, level=1, n_levels=3)
print(results)
```
## Contributing

Contributions to the Langchain Community module are welcome. Whether it's adding support for new document formats, enhancing existing functionality, or fixing bugs, your contributions help improve the module for everyone.

## License

í•´ë‹¹ ì†ŒìŠ¤ì½”ë“œëŠ” `(ì£¼)í¬ë¼ìš°ë“œì›ìŠ¤`ì— ê·€ì†ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
ë¬´ë‹¨ ë°°í¬ ë° ì‚¬ìš©ì„ ê¸ˆí•©ë‹ˆë‹¤.
